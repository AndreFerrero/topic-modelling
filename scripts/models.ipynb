{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%run full_setup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfidf_corpus_dictionary import get_tfidf_tokendocs_corpus_dict\n",
    "from gensim.models import LdaModel, LsiModel, CoherenceModel\n",
    "from sklearn.decomposition import NMF, PCA\n",
    "from sklearn.random_projection import GaussianRandomProjection, SparseRandomProjection\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix, feature_names, tokenized_docs, corpus, dictionary = get_tfidf_tokendocs_corpus_dict(df, max_df=0.5, min_df=5, max_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coherence_by_topics import coherence_by_topics\n",
    "from coherence_by_words import coherence_by_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [5, 10, 20, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_by_topics = {}\n",
    "\n",
    "for n_topics in topics:\n",
    "    metrics_words = coherence_by_topics(n = n_topics, corpus=corpus, dictionary=dictionary,\n",
    "                               texts=tokenized_docs, feature_names=feature_names, tfidf=tfidf_matrix)\n",
    "    \n",
    "    evaluation_by_topics[n_topics] = metrics_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_by_topics[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_by_topics[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_by_topics[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_by_topics[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [10, 100, 1000, 10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_by_words = {}\n",
    "\n",
    "for n_words in words:\n",
    "    metrics_words = coherence_by_words(df, n = n_words)\n",
    "    evaluation_by_words[n_words] = metrics_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_by_words[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_by_words[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_by_words[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_by_words[10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tables(evaluation, type: str):\n",
    "    # Specify the results folder\n",
    "    results = R\"results\"\n",
    "    results_folder = os.path.join(path, results)\n",
    "\n",
    "    # Create individual DataFrames for each specific number\n",
    "    dfs = {}\n",
    "    for n, values in evaluation.items():\n",
    "        dfs[n] = pd.DataFrame(values, columns=['Model', 'Coherence'])\n",
    "\n",
    "    # Save each DataFrame as a PNG file with a title in the specified folder\n",
    "    for n, df in dfs.items():\n",
    "        fig, ax = plt.subplots(figsize=(4, 3))  # Adjust the figure size\n",
    "        ax.axis('off')  # Turn off the axis\n",
    "\n",
    "        # Set the width of the columns\n",
    "        col_width = 1.0 / len(df.columns)\n",
    "        cell_data = [df.columns] + df.values.tolist()  # Include column names as the first row\n",
    "        table = ax.table(cellText=cell_data, loc='center', cellLoc='center', colLabels=None, edges='open')\n",
    "\n",
    "        # Make column labels bold\n",
    "        for (i, j), cell in table.get_celld().items():\n",
    "            if i == 0:\n",
    "                cell.set_text_props(fontweight='bold')\n",
    "\n",
    "        # Adjust column width\n",
    "        table.auto_set_column_width([0, 1])\n",
    "\n",
    "        # Adjust the position of the table within the figure\n",
    "        table.set_fontsize(13)  # Adjust font size\n",
    "        table.scale(1, 2)  # Scale the table\n",
    "\n",
    "        ax.set_title(f'Coherence with {n} {type}', fontsize=18, y=0.95)  # Add a title\n",
    "\n",
    "        filename = os.path.join(results_folder, f'table_{n}_{type}.png')\n",
    "        plt.savefig(filename, bbox_inches='tight', pad_inches=0.1)  # Adjust padding\n",
    "        plt.close()  # Close the figure to avoid overlapping when saving multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables(evaluation_by_topics, 'topics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables(evaluation_by_words, 'words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots(evaluation, type: str):\n",
    "    for n, metrics in evaluation.items():\n",
    "        model_names, coherence_values = zip(*metrics)\n",
    "\n",
    "        # Create a DataFrame for easy plotting with Seaborn\n",
    "        data = {'Model': model_names, 'Coherence Value': coherence_values}\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        \n",
    "        # Use Seaborn's barplot with the hue parameter\n",
    "        sns.barplot(x='Model', y='Coherence Value', data=df, hue='Model', palette='viridis')\n",
    "        \n",
    "        plt.xlabel('Model')\n",
    "        plt.ylabel('Coherence Value')\n",
    "        plt.title(f'Coherence Evaluation for {n} {type}')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        figures_folder = R'C:\\Users\\andre\\OneDrive - Alma Mater Studiorum Universit√† di Bologna\\University\\UniBo\\Machine Learning\\PR1.20\\figures'\n",
    "        save_path = os.path.join(figures_folder, f'coherence_evaluation_{n}_{type}')\n",
    "        \n",
    "        plt.savefig(save_path)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots(evaluation_by_topics, 'topics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots(evaluation_by_words, 'words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from display_topics import display_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll fit the LDA model with the number of topics that yields the highest coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=5,\n",
    "                     alpha='symmetric', eta='auto', passes=5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_topics('LDA', lda_model, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to do the same for LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi_model = LsiModel(corpus, id2word=dictionary, num_topics=5, random_seed = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_topics('LSA', lsi_model, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model = NMF(n_components=5, random_state=1).fit(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_topics('NMF', nmf_model, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix_dense = tfidf_matrix.todense() if sparse.issparse(tfidf_matrix) else tfidf_matrix\n",
    "\n",
    "# Convert to numpy array\n",
    "tfidf_matrix_array = np.asarray(tfidf_matrix_dense)\n",
    "\n",
    "# Centering\n",
    "mean_tfidf = np.mean(tfidf_matrix_array, axis=0)  # Calculate the mean of each column\n",
    "centered_tfidf_matrix = tfidf_matrix_array - mean_tfidf\n",
    "\n",
    "pca_model = PCA(n_components=5, random_state=1).fit(centered_tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_topics('PCA', pca_model, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp_model = GaussianRandomProjection(n_components=5, random_state=1).fit(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_topics('RP', rp_model, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
