{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%run 3-tfidf-gensim.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel, CoherenceModel\n",
    "# %pip install pyldavis==3.3.1\n",
    "import pyLDAvis, pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LDA model uses Dirichlet distributions. The parameters of Dirichlet distributions can be either symmetrical, in which case all the values of the variable will have equal weight, or asymmetrical, where some values have higher weight than others. Moreover, the parameters can be equal to, smaller or greater than 1. For parameters equal to 1, the distribution will assign uniform probability. For values greater than 1, more probability will be assigned to the center, while for values smaller than 1 more probability will be assigned to the corners.\n",
    "\n",
    "In the LDA model, alpha refers to the Dirichlet distribution that assigns documents to topics. For alpha asymmetric, we might risk of having topics more probable than others. For alpha smaller than 1, we are assuming the documents consist of a small number of topics, while for alpha greater than we assume the documents can be composed of more topics. In our case, it'd be better to have a symmetrical alpha, since we don't know if there's a topic much more likely than others.\n",
    "\n",
    "For eta we apply the same logic but with topics and words. Eta smaller than 1 means we're assuming topics are not composed of many words, while Eta greater than 1 we assume more words constitute topics. In this case, it's better to let the model find the proper settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit an LDA model\n",
    "lda_model = LdaModel(corpus=corpus, id2word=id2word, num_topics=6,\n",
    "                     alpha='symmetric', eta='auto', passes=5, random_state=1)\n",
    "\n",
    "auto_alpha = lda_model.alpha\n",
    "auto_eta = lda_model.eta\n",
    "\n",
    "print(f\"Automatically determined alpha: {auto_alpha}\")\n",
    "print(f\"Automatically determined eta: {auto_eta}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coherence is a measure of topics quality returned by the model and can be used for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_model_lda = CoherenceModel(model=lda_model, dictionary = id2word, texts=tokenized_docs, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "\n",
    "print(f'LDA Coherence Score: {coherence_lda}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the LDA model using pyLDAvis\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary=lda_model.id2word, mds='tsne')\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model[corpus]\n",
    "\n",
    "# it returns a list of lists, where each inner list contains tuples where the topic ID and the topic probability are contained\n",
    "# Each inner list is associated to a specific document\n",
    "\n",
    "# output example\n",
    "''' [\n",
    "  DOC1: [(0, 0.05), (1, 0.09), ...]\n",
    "  DOC2: [(0, 0.1), ...]\n",
    "  .\n",
    "  .\n",
    "  .  \n",
    "]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function returns the top words for each topic by highest frequency\n",
    "lda_model.show_topic(0, topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=df['Clean_Content']):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame(columns=['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords'])\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        # we want to sort the tuples in the list 'row' by descending order of the second element, which is the topic probability\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic, i.e. tuple with the highest topic probability\n",
    "                wp = ldamodel.show_topic(topic_num, topn = 15)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df.loc[len(sent_topics_df)] = [int(topic_num), round(prop_topic, 4), topic_keywords]\n",
    "            else:\n",
    "                break\n",
    "    # Add original text to the end of the output\n",
    "    sent_topics_df = pd.concat([sent_topics_df, texts], axis=1)\n",
    "    return sent_topics_df\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_sents_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_sents_keywords['Dominant_Topic'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_distribution = df_topic_sents_keywords.groupby(['Dominant_Topic', 'Topic_Keywords']).size().sort_values(ascending=False).reset_index(name='count')\n",
    "\n",
    "df_topic_distribution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
